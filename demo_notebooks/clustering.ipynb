{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import sys\n",
    "\n",
    "path_to_project = \"/home/path/to/project\"\n",
    "\n",
    "sys.path.append(path_to_project + \"benchmark_VAE/\")\n",
    "sys.path.append(path_to_project + \"benchmark_VAE/src/\")\n",
    "import os\n",
    "import pickle\n",
    "from pythae.models import AutoModel\n",
    "from pythae.ssc.plots import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pythae.ssc.results import EvalPatient, EvaluationDataset\n",
    "from pythae.ssc.utils import load_cv, remove_short_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt paths\n",
    "data_path = path_to_project + \"fake_data/processed/\"\n",
    "figure_path = path_to_project + \"demo_notebooks/plots/\"\n",
    "model_path = (\n",
    "    path_to_project + \"demo_notebooks/saved_models/model_fold_0/\"\n",
    ")\n",
    "\n",
    "name = \"_ml4h\"\n",
    "with open(data_path + \"bodies_\" + name + \".pkl\", \"rb\") as file:\n",
    "    bodies = pickle.load(file)\n",
    "with open(data_path + \"cohorts_\" + name + \".pkl\", \"rb\") as file:\n",
    "    cohorts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables info\n",
    "var_weights0 = [\n",
    "    var.class_weight_norm for var in (bodies[0].variables + bodies[0].labels)\n",
    "]\n",
    "(\n",
    "    data_train_folds,\n",
    "    data_valid_folds,\n",
    "    data_test_folds,\n",
    "    varNames,\n",
    "    varSplits,\n",
    "    xyt0,\n",
    "    xyt1,\n",
    ") = load_cv(data_path, n_folds=2, name=name)\n",
    "var_names0 = [var.name for var in (bodies[0].variables + bodies[0].labels)]\n",
    "\n",
    "names_x0 = [vN for i, vN in enumerate(var_names0) if xyt0[i] == \"x\"]\n",
    "names_y0 = [vN for i, vN in enumerate(var_names0) if xyt0[i] == \"y\"]\n",
    "names_s0 = [vN for i, vN in enumerate(var_names0) if xyt0[i] == \"s\"]\n",
    "\n",
    "kinds_x0 = [\n",
    "    var.kind\n",
    "    for var in (bodies[0].variables + bodies[0].labels)\n",
    "    for nx in names_x0\n",
    "    if var.name == nx\n",
    "]\n",
    "kinds_y0 = [\n",
    "    var.kind\n",
    "    for var in (bodies[0].variables + bodies[0].labels)\n",
    "    for nx in names_y0\n",
    "    if var.name == nx\n",
    "]\n",
    "splits_x0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"x\"]\n",
    "splits_y0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"y\"]\n",
    "splits_s0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"s\"]\n",
    "\n",
    "names_x1 = [vN for i, vN in enumerate(varNames) if xyt1[i] == \"x\"]\n",
    "kinds_x1 = [item for i, spl in enumerate(splits_x0) for item in [kinds_x0[i]] * spl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples of length 0 or 1\n",
    "for i, (data_train, data_valid, data_test) in enumerate(\n",
    "    zip(data_train_folds, data_valid_folds, data_test_folds)\n",
    "):\n",
    "    data_train, data_valid, data_test = remove_short_samples(\n",
    "        data_train, data_valid, data_test\n",
    "    )\n",
    "\n",
    "    data_train_folds[i] = data_train\n",
    "    data_valid_folds[i] = data_valid\n",
    "    data_test_folds[i] = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_training = sorted(os.listdir(model_path))[-1]\n",
    "model = AutoModel.load_from_folder(\n",
    "    os.path.join(model_path, last_training, \"final_model\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to cpu\n",
    "model.cpu()\n",
    "model.device = \"cpu\"\n",
    "model.classifiers = [classif.cpu() for classif in model.classifiers]\n",
    "model.encoder.device = \"cpu\"\n",
    "model.decoder.device = \"cpu\"\n",
    "fold = 0\n",
    "data_train = data_train_folds[fold]\n",
    "data_valid = data_valid_folds[fold]\n",
    "data_test = data_test_folds[fold]\n",
    "body = bodies[fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=70,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = EvaluationDataset(\n",
    "    data_test,\n",
    "    model,\n",
    "    body,\n",
    "    splits_x0,\n",
    "    names_x0,\n",
    "    kinds_x0,\n",
    "    splits_y0,\n",
    "    names_y0,\n",
    "    kinds_y0,\n",
    "    names_s0,\n",
    "    kinds_x1,\n",
    "    names_x1,\n",
    "    len(data_test),\n",
    ")\n",
    "evaluation.evaluate(num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on train\n",
    "sample_batch_train = data_train.get_ith_sample_batch_with_customDataLoader(0, 1400)\n",
    "out_train = model(sample_batch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_train = sample_batch_train[\"splits\"]\n",
    "indices_recon_train = torch.cat(\n",
    "    [\n",
    "        torch.cat(\n",
    "            [\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        torch.full((index, 1), True),\n",
    "                        torch.full((splits_train[pat] - index, 1), False),\n",
    "                    ],\n",
    "                    dim=0,\n",
    "                )\n",
    "                for index in range(0, splits_train[pat] + 1)\n",
    "            ]\n",
    "        )\n",
    "        for pat in range(len(splits_train))\n",
    "    ]\n",
    ").flatten()\n",
    "# fit only on reconstruction indices\n",
    "z_tsne_train = tsne.fit(out_train.z[indices_recon_train].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tsne_test = z_tsne_train.transform(\n",
    "    evaluation.predictions.z[evaluation.indices_recon].detach()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_arrays_recon = np.split(\n",
    "    evaluation.non_missing_y_recon[evaluation.indices_recon],\n",
    "    np.cumsum(evaluation.splits_y0[:-1]),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import TimeSeriesKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"dtw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_recon_train_full = torch.cat(\n",
    "    [\n",
    "        torch.cat(\n",
    "            [\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        torch.full((index, 1), True),\n",
    "                        torch.full((splits_train[pat] - index, 1), False),\n",
    "                    ],\n",
    "                    dim=0,\n",
    "                )\n",
    "                for index in range(0, splits_train[pat] + 1)\n",
    "            ]\n",
    "        )\n",
    "        for pat in range(len(splits_train))\n",
    "    ]\n",
    ").flatten()\n",
    "DATA_train = torch.split(out_train.z, [elem * (elem + 1) for elem in splits_train])\n",
    "DATA_train = [\n",
    "    torch.split(elem, [splits_train[index]] * (splits_train[index] + 1))\n",
    "    for index, elem in enumerate(DATA_train)\n",
    "]\n",
    "DATA_train_splitted = [elem[-1] for elem in DATA_train]\n",
    "DATA_train = torch.cat(DATA_train_splitted)\n",
    "DATA_train_ts = torch.split(DATA_train, splits_train, dim=0)\n",
    "DATA_train_ts = [elem.detach().numpy() for elem in DATA_train_ts]\n",
    "DATA_train_ts = to_time_series_dataset(DATA_train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_test = torch.split(\n",
    "    evaluation.predictions.z, [elem * (elem + 1) for elem in evaluation.splits]\n",
    ")\n",
    "DATA_test = [\n",
    "    torch.split(elem, [evaluation.splits[index]] * (evaluation.splits[index] + 1))\n",
    "    for index, elem in enumerate(DATA_test)\n",
    "]\n",
    "DATA_test = torch.cat([elem[-1] for elem in DATA_test])\n",
    "DATA_test_ts = torch.split(DATA_test, evaluation.splits, dim=0)\n",
    "DATA_test_ts = [elem.detach().numpy() for elem in DATA_test_ts]\n",
    "DATA_test_ts = to_time_series_dataset(DATA_test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KM = TimeSeriesKMeans(\n",
    "    n_clusters=3, metric=metric, max_iter=30, random_state=0, n_jobs=-1\n",
    ")\n",
    "model_KM.fit(DATA_train_ts)\n",
    "clusters_train = model_KM.predict(DATA_train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_means1 = model_KM.cluster_centers_\n",
    "embedding_means1 = z_tsne_train.transform(\n",
    "    z_means1.reshape(-1, model_KM.cluster_centers_.shape[-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "titles = {\n",
    "    0: \"Lung involvement\",\n",
    "    4: \"Arthritis involvement\",\n",
    "    2: \"Heart involvement\",\n",
    "    1: \"Lung stage\",\n",
    "    5: \"Arthritis stage\",\n",
    "    3: \"Heart stage\",\n",
    "}\n",
    "cluster_colors = [\"blue\", \"orange\", \"red\"]\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 6), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "for j, (label_index, title) in enumerate(titles.items()):\n",
    "    row = j // 3  # Calculate the row index\n",
    "    col = j % 3  # Calculate the column index\n",
    "    ax = axs[row, col]\n",
    "\n",
    "    if title in [\"Lung involvement\", \"Heart involvement\", \"Arthritis involvement\"]:\n",
    "        overlay_color = evaluation.res_list_y[label_index][1].detach()\n",
    "        colorbar_vmin = 0\n",
    "        colorbar_vmax = 1\n",
    "        color = overlay_color[evaluation.indices_recon]\n",
    "        name_cbar = \"Probability\"\n",
    "    else:\n",
    "        overlay_color = evaluation.predicted_cats_y\n",
    "        colorbar_vmin = np.nanmin(\n",
    "            np.array(overlay_color[evaluation.indices_recon][:, label_index])\n",
    "        )\n",
    "        colorbar_vmax = np.nanmax(\n",
    "            np.array(overlay_color[evaluation.indices_recon][:, label_index])\n",
    "        )\n",
    "        color = overlay_color[evaluation.indices_recon][:, label_index]\n",
    "        name_cbar = \"Stage\"\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        z_tsne_test[:, 0],\n",
    "        z_tsne_test[:, 1],\n",
    "        c=color,\n",
    "        alpha=0.5,\n",
    "        vmin=colorbar_vmin,\n",
    "        vmax=colorbar_vmax,\n",
    "        s=2,\n",
    "    )\n",
    "    for c_index, (i_1, i_2) in enumerate([(28, 42), (0, 14), (14, 28)]):\n",
    "        ax.plot(\n",
    "            embedding_means1[i_1:i_2][0, 0],\n",
    "            embedding_means1[i_1:i_2][0, 1],\n",
    "            marker=\"x\",\n",
    "            markersize=7,\n",
    "            markeredgewidth=3,\n",
    "            color=cluster_colors[c_index],\n",
    "        )\n",
    "\n",
    "        ax.plot(\n",
    "            embedding_means1[i_1:i_2][:, 0],\n",
    "            embedding_means1[i_1:i_2][:, 1],\n",
    "            label=f\"mean trajectory\\nof cluster {c_index + 1}\",\n",
    "            color=cluster_colors[c_index],\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "    ax.set_title(titles[label_index])\n",
    "\n",
    "    ax.grid(linestyle=\"--\")\n",
    "\n",
    "    if (row == 1) & (col == 2):\n",
    "        sm = cm.ScalarMappable(\n",
    "            cmap=scatter.get_cmap(),\n",
    "            norm=plt.Normalize(vmin=colorbar_vmin, vmax=colorbar_vmax),\n",
    "        )\n",
    "        sm.set_array([])  # Set an empty array to ensure correct color mapping\n",
    "        cbar_ax = fig.add_axes(\n",
    "            [\n",
    "                axs[1, 2].get_position().x1 + 0.01,\n",
    "                axs[1, 2].get_position().y0,\n",
    "                0.02,\n",
    "                axs[1, 2].get_position().height,\n",
    "            ]\n",
    "        )\n",
    "        cbar_ax = fig.colorbar(\n",
    "            sm, cax=cbar_ax, fraction=0.046, pad=0.04, ticks=[1, 2, 3, 4]\n",
    "        )\n",
    "        cbar_ax.ax.set_ylabel(\"Stage\")\n",
    "    if (row == 0) & (col == 2):\n",
    "        sm = cm.ScalarMappable(\n",
    "            cmap=scatter.get_cmap(),\n",
    "            norm=plt.Normalize(vmin=colorbar_vmin, vmax=colorbar_vmax),\n",
    "        )\n",
    "        sm.set_array([])  # Set an empty array to ensure correct color mapping\n",
    "        cbar_ax = fig.add_axes(\n",
    "            [\n",
    "                axs[0, 2].get_position().x1 + 0.01,\n",
    "                axs[0, 2].get_position().y0,\n",
    "                0.02,\n",
    "                axs[0, 2].get_position().height,\n",
    "            ]\n",
    "        )\n",
    "        cbar_ax = fig.colorbar(sm, cax=cbar_ax, fraction=0.046, pad=0.04, ticks=[0, 1])\n",
    "        cbar_ax.ax.set_ylabel(\"Probability\")\n",
    "ax.legend(fontsize=\"small\", bbox_to_anchor=(2, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.neighbors import KNeighborsTimeSeries\n",
    "from tslearn.utils import to_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh = 3\n",
    "knn_ts = KNeighborsTimeSeries(n_neighbors=k_neigh, metric=metric)\n",
    "\n",
    "knn_ts.fit(DATA_train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_p = EvalPatient(\n",
    "    data_test,\n",
    "    model,\n",
    "    body,\n",
    "    splits_x0,\n",
    "    names_x0,\n",
    "    kinds_x0,\n",
    "    splits_y0,\n",
    "    names_y0,\n",
    "    kinds_y0,\n",
    "    names_s0,\n",
    "    kinds_x1,\n",
    "    names_x1,\n",
    "    1,\n",
    "    batch_num=random.choice(range(len(data_test))),\n",
    ")\n",
    "eval_p.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_test_pat = torch.split(\n",
    "    eval_p.predictions.z, [elem * (elem + 1) for elem in eval_p.splits]\n",
    ")\n",
    "DATA_test_pat = [\n",
    "    torch.split(elem, [eval_p.splits[index]] * (eval_p.splits[index] + 1))\n",
    "    for index, elem in enumerate(DATA_test_pat)\n",
    "]\n",
    "DATA_test_pat_splitted = [elem[-1] for elem in DATA_test_pat]\n",
    "DATA_test_pat = torch.cat(DATA_test_pat_splitted)\n",
    "DATA_test_ts_pat = torch.split(DATA_test_pat, eval_p.splits, dim=0)\n",
    "DATA_test_ts_pat = [elem.detach().numpy() for elem in DATA_test_ts_pat]\n",
    "DATA_test_ts_pat = to_time_series(DATA_test_ts_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_neigh = knn_ts.kneighbors(DATA_test_ts_pat, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tsnes = []\n",
    "for p in nn_neigh[1].flatten():\n",
    "    nn_tsnes.append(z_tsne_train.transform(DATA_train_splitted[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_pat = z_tsne_train.transform(DATA_test_pat_splitted[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "titles = {\n",
    "    0: \"Lung involvement\",\n",
    "    4: \"Arthritis involvement\",\n",
    "    2: \"Heart involvement\",\n",
    "    1: \"Lung stage\",\n",
    "    5: \"Arthritis stage\",\n",
    "    3: \"Heart stage\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 6), sharex=True, sharey=True)\n",
    "\n",
    "nn_colors = [\"blue\", \"black\", \"green\"]\n",
    "for j, (label_index, title) in enumerate(titles.items()):\n",
    "    row = j // 3  # Calculate the row index\n",
    "    col = j % 3  # Calculate the column index\n",
    "    ax = axs[row, col]\n",
    "    indices = list_of_arrays_recon[label_index].all(axis=1)\n",
    "\n",
    "    if title in [\"Lung involvement\", \"Heart involvement\", \"Arthritis involvement\"]:\n",
    "        overlay_color = evaluation.res_list_y[label_index][1].detach()\n",
    "        colorbar_vmin = 0\n",
    "        colorbar_vmax = 1\n",
    "        color = overlay_color[evaluation.indices_recon][indices]\n",
    "        name_cbar = \"Probability\"\n",
    "    else:\n",
    "        overlay_color = evaluation.predicted_cats_y\n",
    "        colorbar_vmin = np.nanmin(\n",
    "            np.array(overlay_color[evaluation.indices_recon][:, label_index])\n",
    "        )\n",
    "        colorbar_vmax = np.nanmax(\n",
    "            np.array(overlay_color[evaluation.indices_recon][:, label_index])\n",
    "        )\n",
    "        color = overlay_color[evaluation.indices_recon][:, label_index]\n",
    "        name_cbar = \"Stage\"\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        z_tsne_test[:, 0],\n",
    "        z_tsne_test[:, 1],\n",
    "        c=color,\n",
    "        alpha=0.5,\n",
    "        vmin=colorbar_vmin,\n",
    "        vmax=colorbar_vmax,\n",
    "        s=2,\n",
    "    )\n",
    "\n",
    "    ax.plot(tsne_pat[:, 0], tsne_pat[:, 1], color=\"red\", lw=1.5, label=f\"$p$\")\n",
    "    ax.plot(\n",
    "        tsne_pat[0, 0],\n",
    "        tsne_pat[0, 1],\n",
    "        marker=\"x\",\n",
    "        markersize=7,\n",
    "        markeredgewidth=3,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    for i_nn, ts in enumerate(nn_tsnes):\n",
    "        ax.plot(\n",
    "            ts[0, 0],\n",
    "            ts[0, 1],\n",
    "            marker=\"x\",\n",
    "            markersize=7,\n",
    "            markeredgewidth=3,\n",
    "            color=nn_colors[i_nn],\n",
    "        )\n",
    "        ax.plot(\n",
    "            ts[:, 0], ts[:, 1], color=nn_colors[i_nn], lw=1.5, label=f\"nn {i_nn + 1}\"\n",
    "        )\n",
    "\n",
    "    ax.set_title(titles[label_index])\n",
    "    ax.grid(linestyle=\"--\")\n",
    "    if (row == 1) & (col == 2):\n",
    "        sm = cm.ScalarMappable(\n",
    "            cmap=scatter.get_cmap(),\n",
    "            norm=plt.Normalize(vmin=colorbar_vmin, vmax=colorbar_vmax),\n",
    "        )\n",
    "        sm.set_array([])  # Set an empty array to ensure correct color mapping\n",
    "        cbar_ax = fig.add_axes(\n",
    "            [\n",
    "                axs[1, 2].get_position().x1 + 0.01,\n",
    "                axs[1, 2].get_position().y0,\n",
    "                0.02,\n",
    "                axs[1, 2].get_position().height,\n",
    "            ]\n",
    "        )\n",
    "        cbar_ax = fig.colorbar(\n",
    "            sm, cax=cbar_ax, fraction=0.046, pad=0.04, ticks=[1, 2, 3, 4]\n",
    "        )\n",
    "        cbar_ax.ax.set_ylabel(\"Stage\")\n",
    "    if (row == 0) & (col == 2):\n",
    "        sm = cm.ScalarMappable(\n",
    "            cmap=scatter.get_cmap(),\n",
    "            norm=plt.Normalize(vmin=colorbar_vmin, vmax=colorbar_vmax),\n",
    "        )\n",
    "        sm.set_array([])  # Set an empty array to ensure correct color mapping\n",
    "        cbar_ax = fig.add_axes(\n",
    "            [\n",
    "                axs[0, 2].get_position().x1 + 0.01,\n",
    "                axs[0, 2].get_position().y0,\n",
    "                0.02,\n",
    "                axs[0, 2].get_position().height,\n",
    "            ]\n",
    "        )\n",
    "        cbar_ax = fig.colorbar(sm, cax=cbar_ax, fraction=0.046, pad=0.04, ticks=[0, 1])\n",
    "        cbar_ax.ax.set_ylabel(\"Probability\")\n",
    "ax.legend(fontsize=\"small\", bbox_to_anchor=(2, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
