{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "# adapt paths\n",
    "path_to_project = \"/home/path/to/project\"\n",
    "\n",
    "\n",
    "sys.path.append(path_to_project + \"benchmark_VAE/\")\n",
    "sys.path.append(path_to_project + \"benchmark_VAE/src/\")\n",
    "\n",
    "\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "from pythae.models import BetaVAEgpCondInd\n",
    "from pythae.models import (\n",
    "    BetaVAEgpCondIndConfig,\n",
    ")\n",
    "from pythae.models.beta_vae_gp.encoder_decoder import (\n",
    "    Indep_MLP_Decoder,\n",
    "    Guidance_Classifier,\n",
    "    LSTM_Encoder,\n",
    "    LSTM_Retrodiction_Decoder,\n",
    ")\n",
    "\n",
    "from pythae.ssc.utils import (\n",
    "    load_cv,\n",
    "    get_classifier_config,\n",
    "    remove_short_samples,\n",
    ")\n",
    "\n",
    "from pythae.models.beta_vae_gp.classifier_config import (\n",
    "    EncoderDecoderConfig,\n",
    "    PriorLatentConfig,\n",
    "    DecoderConfig,\n",
    ")\n",
    "from pythae.models.beta_vae_gp.prior_latent import PriorLatent\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from pythae.ssc.plots import plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# adapt path\n",
    "data_path = path_to_project + \"fake_data/processed/\"\n",
    "name = \"_ml4h\"\n",
    "\n",
    "# load bodies and cohorts, they have to be generate first by running the ssc/create_cv.py script\n",
    "with open(data_path + \"bodies_\" + name + \".pkl\", \"rb\") as file:\n",
    "    bodies = pickle.load(file)\n",
    "with open(data_path + \"cohorts_\" + name + \".pkl\", \"rb\") as file:\n",
    "    cohorts = pickle.load(file)\n",
    "\n",
    "(\n",
    "    data_train_folds,\n",
    "    data_valid_folds,\n",
    "    data_test_folds,\n",
    "    varNames,\n",
    "    varSplits,\n",
    "    xyt0,\n",
    "    xyt1,\n",
    ") = load_cv(data_path, n_folds=2, name=name)\n",
    "\n",
    "# variable names\n",
    "var_names0 = [var.name for var in (bodies[0].variables + bodies[0].labels)]\n",
    "var_weights0 = [\n",
    "    var.class_weight_norm for var in (bodies[0].variables + bodies[0].labels)\n",
    "]\n",
    "\n",
    "names_x0 = [vN for i, vN in enumerate(var_names0) if xyt0[i] == \"x\"]\n",
    "names_y0 = [vN for i, vN in enumerate(var_names0) if xyt0[i] == \"y\"]\n",
    "weights_x0 = [vW for i, vW in enumerate(var_weights0) if xyt0[i] == \"x\"]\n",
    "weights_y0 = [vW for i, vW in enumerate(var_weights0) if xyt0[i] == \"y\"]\n",
    "\n",
    "kinds_x0 = [\n",
    "    var.kind\n",
    "    for var in (bodies[0].variables + bodies[0].labels)\n",
    "    for nx in names_x0\n",
    "    if var.name == nx\n",
    "]\n",
    "kinds_y0 = [\n",
    "    var.kind\n",
    "    for var in (bodies[0].variables + bodies[0].labels)\n",
    "    for nx in names_y0\n",
    "    if var.name == nx\n",
    "]\n",
    "splits_x0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"x\"]\n",
    "splits_y0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"y\"]\n",
    "splits_s0 = [vN for i, vN in enumerate(varSplits) if xyt0[i] == \"s\"]\n",
    "# remove samples of length 0 or 1\n",
    "for i, (data_train, data_valid, data_test) in enumerate(\n",
    "    zip(data_train_folds, data_valid_folds, data_test_folds)\n",
    "):\n",
    "    data_train, data_valid, data_test = remove_short_samples(\n",
    "        data_train, data_valid, data_test\n",
    "    )\n",
    "\n",
    "    data_train_folds[i] = data_train\n",
    "    data_valid_folds[i] = data_valid\n",
    "    data_test_folds[i] = data_test\n",
    "\n",
    "input_size = sum(splits_x0)\n",
    "\n",
    "static_size = sum(splits_s0)\n",
    "latent_dim = 21\n",
    "model_name = \"VAE\"\n",
    "\n",
    "params = {\n",
    "    \"dropout\": 0.1,\n",
    "    \"lstm_hidden_size\": 100,\n",
    "    \"num_lstm_layers\": 1,\n",
    "    \"hidden_dims_enc\": [100, 100],\n",
    "    \"hidden_dims_emb_dec\": [100],\n",
    "    \"hidden_dims_log_var_dec\": [100],\n",
    "    \"classif_layers\": [40],\n",
    "}\n",
    "\n",
    "# can be changed to train different models\n",
    "sample_ = True\n",
    "fixed_variance = False\n",
    "\n",
    "# to create classifier configs. Specify each classifier name, variables to predict in y, z dimensions to use and architecture of the classifier\n",
    "classifier_config = {\n",
    "    \"lung_inv\": {\n",
    "        \"y_names\": [\"LUNG_ILD_involvement_or\"],\n",
    "        \"z_dims\": np.arange(0, 7),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "    \"lung_stage\": {\n",
    "        \"y_names\": [\"LUNG_ILD_stage_or\"],\n",
    "        \"z_dims\": np.arange(0, 7),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "    \"heart_inv\": {\n",
    "        \"y_names\": [\"HEART_involvement_or\"],\n",
    "        \"z_dims\": np.arange(7, 14),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "    \"heart_stage\": {\n",
    "        \"y_names\": [\"HEART_stage_or\"],\n",
    "        \"z_dims\": np.arange(7, 14),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "    \"arthritis_inv\": {\n",
    "        \"y_names\": [\"ARTHRITIS_involvement_or\"],\n",
    "        \"z_dims\": np.arange(14, 21),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "    \"arthritis_stage\": {\n",
    "        \"y_names\": [\"ARTHRITIS_stage_or\"],\n",
    "        \"z_dims\": np.arange(14, 21),\n",
    "        \"layers\": params[\"classif_layers\"],\n",
    "        \"type\": \"static\",\n",
    "    },\n",
    "}\n",
    "# weights for the different losses\n",
    "beta = 0.01\n",
    "w_class = {\n",
    "    \"lung_inv\": 0.2,\n",
    "    \"lung_stage\": 0.2,\n",
    "    \"heart_inv\": 0.2,\n",
    "    \"heart_stage\": 0.2,\n",
    "    \"arthritis_inv\": 0.2,\n",
    "    \"arthritis_stage\": 0.2,\n",
    "}\n",
    "\n",
    "w_recon = 1\n",
    "w_class_pred = {\n",
    "    \"lung_inv\": 0.2,\n",
    "    \"lung_stage\": 0.2,\n",
    "    \"heart_inv\": 0.2,\n",
    "    \"heart_stage\": 0.2,\n",
    "    \"arthritis_inv\": 0.2,\n",
    "    \"arthritis_stage\": 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "classifier_configs = get_classifier_config(names_y0, splits_y0, classifier_config)\n",
    "\n",
    "encoder_config = EncoderDecoderConfig.from_dict(\n",
    "    {\n",
    "        \"input_dim\": input_size + static_size,\n",
    "        \"output_dim\": latent_dim,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"hidden_dims\": params[\"hidden_dims_enc\"],\n",
    "        \"cond_dim_time_input\": 1,\n",
    "        \"lstm_\": True,\n",
    "        \"lstm_hidden_size\": params[\"lstm_hidden_size\"],\n",
    "        \"num_lstm_layers\": params[\"num_lstm_layers\"],\n",
    "        \"device\": device,\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"predict\": True,\n",
    "    }\n",
    ")\n",
    "decoder_config = DecoderConfig.from_dict(\n",
    "    {\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"output_dim\": input_size,\n",
    "        \"fixed_variance\": fixed_variance,\n",
    "        \"hidden_dims\": [],\n",
    "        \"hidden_dims_emb\": params[\"hidden_dims_emb_dec\"],\n",
    "        \"hidden_dims_log_var\": params[\"hidden_dims_log_var_dec\"],\n",
    "        \"cond_dim_time_latent\": 1,\n",
    "        \"cond_dim_static_latent\": static_size,\n",
    "        \"lstm_\": False,\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"device\": device,\n",
    "    }\n",
    ")\n",
    "\n",
    "prior_config = PriorLatentConfig.from_dict(\n",
    "    {\n",
    "        \"input_dim\": 1 + static_size,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"hidden_dims\": [50],\n",
    "        \"device\": device,\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "to_reconstruct_x = [(name, index, True) for index, name in enumerate(names_x0)]\n",
    "\n",
    "to_reconstruct_y = [(name, index, True) for index, name in enumerate(names_y0)]\n",
    "model_config = BetaVAEgpCondIndConfig(\n",
    "    input_dim=(input_size,),\n",
    "    sample=sample_,\n",
    "    latent_dim=latent_dim,\n",
    "    w_class=w_class,\n",
    "    w_recon=w_recon,\n",
    "    beta=beta,\n",
    "    w_class_pred=w_class_pred,\n",
    "    missing_loss=True,\n",
    "    latent_prior_noise_var=1,\n",
    "    classifier_config=classifier_configs,\n",
    "    encoder_config=encoder_config,\n",
    "    decoder_config=decoder_config,\n",
    "    prior_config=prior_config,\n",
    "    splits_x0=splits_x0,\n",
    "    kinds_x0=kinds_x0,\n",
    "    splits_y0=splits_y0,\n",
    "    kinds_y0=kinds_y0,\n",
    "    names_x0=names_x0,\n",
    "    weights_x0=weights_x0,\n",
    "    weights_y0=weights_y0,\n",
    "    to_reconstruct_x=to_reconstruct_x,\n",
    "    to_reconstruct_y=to_reconstruct_y,\n",
    "    device=device,\n",
    "    predict=True,\n",
    "    retrodiction=False,\n",
    "    progression=False,\n",
    ")\n",
    "\n",
    "k = 0\n",
    "print(f\"Training on fold {k}\")\n",
    "\n",
    "output_dir = \"saved_models/model_fold_\" + str(k) + \"/\"\n",
    "config = BaseTrainerConfig(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=100,\n",
    "    num_epochs=50,\n",
    "    customized=True,\n",
    ")\n",
    "\n",
    "my_encoder = LSTM_Encoder(encoder_config)\n",
    "\n",
    "if decoder_config.lstm_:\n",
    "    my_decoder = LSTM_Retrodiction_Decoder(decoder_config)\n",
    "else:\n",
    "    my_decoder = Indep_MLP_Decoder(decoder_config)\n",
    "\n",
    "if prior_config is not None:\n",
    "    prior_latent = PriorLatent(prior_config)\n",
    "else:\n",
    "    prior_latent = None\n",
    "\n",
    "my_classifiers = [\n",
    "    Guidance_Classifier(config) for config in model_config.classifier_config\n",
    "]\n",
    "\n",
    "model = BetaVAEgpCondInd(\n",
    "    model_config=model_config,\n",
    "    encoder=my_encoder,\n",
    "    decoder=my_decoder,\n",
    "    classifiers=my_classifiers,\n",
    "    prior_latent=prior_latent,\n",
    ")\n",
    "\n",
    "pipeline = TrainingPipeline(training_config=config, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "pipeline(train_data=data_train_folds[k], eval_data=data_valid_folds[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
